{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Append '/usr/bin/' to the PATH\n",
    "os.environ['PATH'] += os.pathsep + '/usr/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:11:12:13:14:15\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /workspaces/vosk-api/python/renzo/model1/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /workspaces/vosk-api/python/renzo/model1/graph/HCLr.fst /workspaces/vosk-api/python/renzo/model1/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /workspaces/vosk-api/python/renzo/model1/graph/phones/word_boundary.int\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# Path to your Vosk model\n",
    "model_path = \"/workspaces/vosk-api/python/renzo/model1\"  # Update with your actual model path\n",
    "\n",
    "# Initialize the Vosk model\n",
    "model = Model(model_path)\n",
    "\n",
    "# Create a KaldiRecognizer with the model and sampling rate\n",
    "recognizer = KaldiRecognizer(model, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to capture audio from Twitch\n",
    "twitch_channel = \"twitch_channel_name\"  # Replace with the Twitch channel name\n",
    "\n",
    "streamlink_command = [\n",
    "    \"streamlink\",\n",
    "    f\"twitch.tv/{twitch_channel}\",\n",
    "    \"audio_only\",\n",
    "    \"--stdout\",  # Output to stdout\n",
    "]\n",
    "\n",
    "ffmpeg_path = '/usr/bin/ffmpeg'  # Replace with the actual path from 'which ffmpeg'\n",
    "ffmpeg_command = [\n",
    "    \"ffmpeg\",\n",
    "    \"-loglevel\", \"quiet\",  # Suppress ffmpeg output if desired\n",
    "    \"-i\", \"pipe:0\",        # Input from stdin\n",
    "    \"-ac\", \"1\",            # Mono audio\n",
    "    \"-ar\", \"16000\",        # Sampling rate 16000 Hz\n",
    "    \"-f\", \"s16le\",         # Output format\n",
    "    \"pipe:1\",              # Output to stdout\n",
    "]\n",
    "\n",
    "# Start the streamlink process\n",
    "streamlink_process = subprocess.Popen(\n",
    "    streamlink_command,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "# Start the ffmpeg process\n",
    "ffmpeg_process = subprocess.Popen(\n",
    "    ffmpeg_command,\n",
    "    stdin=streamlink_process.stdout,  # Get input from streamlink process\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "# Ensure that streamlink_process.stdout doesn't get closed when ffmpeg_process exits\n",
    "streamlink_process.stdout.close()\n",
    "\n",
    "# Read audio data and transcribe\n",
    "try:\n",
    "    while True:\n",
    "        data = ffmpeg_process.stdout.read(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = recognizer.Result()\n",
    "            text = json.loads(result)[\"text\"]\n",
    "            if text:\n",
    "                print(f\"Transcript: {text}\")\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            partial_text = json.loads(partial_result)[\"partial\"]\n",
    "            # You can print partial results if desired\n",
    "            # print(f\"Partial: {partial_text}\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    ffmpeg_process.kill()\n",
    "    streamlink_process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitch_channel = \"renzoscriber\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to create a `test_output.ts` file:\n",
    "\n",
    "`streamlink twitch.tv/renzoscriber audio_only --stdout > test_output.ts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/vosk-api/.venv/bin:/vscode/bin/linux-x64/fabdb6a30b49f79a7aba0f2ad9df9b399473380f/bin/remote-cli:/home/codespace/.local/bin:/home/codespace/.dotnet:/home/codespace/nvm/current/bin:/home/codespace/.php/current/bin:/home/codespace/.python/current/bin:/home/codespace/java/current/bin:/home/codespace/.ruby/current/bin:/home/codespace/.local/bin:/usr/local/python/current/bin:/usr/local/py-utils/bin:/usr/local/oryx:/usr/local/go/bin:/go/bin:/usr/local/sdkman/bin:/usr/local/sdkman/candidates/java/current/bin:/usr/local/sdkman/candidates/gradle/current/bin:/usr/local/sdkman/candidates/maven/current/bin:/usr/local/sdkman/candidates/ant/current/bin:/usr/local/rvm/gems/default/bin:/usr/local/rvm/gems/default@global/bin:/usr/local/rvm/rubies/default/bin:/usr/local/share/rbenv/bin:/usr/local/php/current/bin:/opt/conda/bin:/usr/local/nvs:/usr/local/share/nvm/current/bin:/usr/local/hugo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/share/dotnet:/home/codespace/.dotnet/tools:/usr/local/rvm/bin:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:11:12:13:14:15\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /workspaces/vosk-api/python/renzo/model1/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /workspaces/vosk-api/python/renzo/model1/graph/HCLr.fst /workspaces/vosk-api/python/renzo/model1/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /workspaces/vosk-api/python/renzo/model1/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: the\n",
      "Transcript: the\n",
      "Transcript: my name\n",
      "Transcript: okay\n",
      "Transcript: so\n",
      "Transcript: we don't want to look at that\n",
      "Transcript: i was i i was kind of successful tonight\n",
      "Transcript: where is where my results\n",
      "Transcript: haha my transcript from my test stream\n",
      "Transcript: that a she\n",
      "Transcript: it says that thing okay us and canada stream discussion to discontinue it he\n",
      "Transcript: this is what is unsupported will result in incoherent output data oh no is\n",
      "Transcript: how appropriate okay that's okay that is totally fine are do remember saying that so let me see here okay so what did i want to see oh\n",
      "Transcript: i know okay so it looks like i have good what's it called streaming no not streaming wifi whatever sorry on a little poo brain and that's how i knew it was definitely me but i'm excited i think i got it to work knock on wood i i'm going to end\n",
      "Transcript: this dream see what happens when i do that\n",
      "Transcript: and then i\n",
      "Transcript: and then i ended the stream\n",
      "Transcript: in that cool\n",
      "Transcript: i am low key hype\n",
      "Transcript: how do i ended without and in the stream shit\n",
      "Transcript: i've no idea\n",
      "Transcript: i\n",
      "Transcript: hm\n",
      "Transcript: what do i want to do where do i want to go from here\n",
      "Transcript: i think i'm going to end stream again\n",
      "Transcript: and\n",
      "Transcript: close out all this nonsense\n",
      "Transcript: and then play game an impasse out\n",
      "Transcript: very good\n",
      "FFmpeg Error: ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "[mpegts @ 0x5a969b3c8700] DTS discontinuity in stream 2: packet 3 with DTS 5760090, packet 4 with DTS 5940000\n",
      "Input #0, mpegts, from '/workspaces/vosk-api/test_output0.ts':\n",
      "  Duration: 00:03:19.07, start: 62.000000, bitrate: 442 kb/s\n",
      "  Program 1 \n",
      "    Stream #0:0[0x100]: Audio: aac (LC) ([15][0][0][0] / 0x000F), 48000 Hz, stereo, fltp, 127 kb/s\n",
      "    Stream #0:1[0x101]: Video: h264 (Main) ([27][0][0][0] / 0x001B), yuv420p(progressive), 1920x1080, 30 fps, 30 tbr, 90k tbn, 2k tbc\n",
      "    Stream #0:2[0x102]: Data: timed_id3 (ID3  / 0x20334449)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, s16le, to 'pipe:1':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: pcm_s16le, 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 pcm_s16le\n",
      "size=    5194kB time=00:02:46.18 bitrate= 256.0kbits/s speed=3.88x    \n",
      "video:0kB audio:5194kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "# Ensure ffmpeg is in PATH\n",
    "os.environ['PATH'] += os.pathsep + '/usr/bin/'\n",
    "\n",
    "# Verify PATH (optional)\n",
    "print(os.environ['PATH'])\n",
    "\n",
    "# Path to your Vosk model\n",
    "model_path = \"/workspaces/vosk-api/python/renzo/model1\"  # Update with your actual model path\n",
    "\n",
    "# Initialize the Vosk model\n",
    "model = Model(model_path)\n",
    "\n",
    "# Create a KaldiRecognizer with the model and sampling rate\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "# FFmpeg command to read from test_output.ts instead of live stream\n",
    "ffmpeg_command = [\n",
    "    'ffmpeg',\n",
    "    \"-i\", \"/workspaces/vosk-api/test_output0.ts\",     # Use the .ts file as input\n",
    "    \"-ac\", \"1\",                 # Mono audio\n",
    "    \"-ar\", \"16000\",             # Sampling rate 16000 Hz\n",
    "    \"-f\", \"s16le\",              # Output format\n",
    "    \"pipe:1\",                   # Output to stdout\n",
    "]\n",
    "\n",
    "# Start the ffmpeg process to convert the .ts file to raw audio\n",
    "ffmpeg_process = subprocess.Popen(\n",
    "    ffmpeg_command,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,   # Capture stderr for debugging\n",
    ")\n",
    "\n",
    "# Read audio data and transcribe\n",
    "try:\n",
    "    while True:\n",
    "        data = ffmpeg_process.stdout.read(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = recognizer.Result()\n",
    "            text = json.loads(result)[\"text\"]\n",
    "            if text:\n",
    "                print(f\"Transcript: {text}\")\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            partial_text = json.loads(partial_result)[\"partial\"]\n",
    "            # You can print partial results if desired\n",
    "            # print(f\"Partial: {partial_text}\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    # Read and print any errors from ffmpeg before closing and killing the process\n",
    "    ffmpeg_errors = ffmpeg_process.stderr.read().decode('utf-8')\n",
    "    if ffmpeg_errors:\n",
    "        print(f\"FFmpeg Error: {ffmpeg_errors}\")\n",
    "\n",
    "    # Close and kill the process\n",
    "    ffmpeg_process.stderr.close()\n",
    "    ffmpeg_process.stdout.close()\n",
    "    ffmpeg_process.kill()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
