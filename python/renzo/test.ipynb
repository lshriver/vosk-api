{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/vosk-api/venv/bin:/vscode/bin/linux-x64/fabdb6a30b49f79a7aba0f2ad9df9b399473380f/bin/remote-cli:/home/codespace/.local/bin:/home/codespace/.dotnet:/home/codespace/nvm/current/bin:/home/codespace/.php/current/bin:/home/codespace/.python/current/bin:/home/codespace/java/current/bin:/home/codespace/.ruby/current/bin:/home/codespace/.local/bin:/usr/local/python/current/bin:/usr/local/py-utils/bin:/usr/local/oryx:/usr/local/go/bin:/go/bin:/usr/local/sdkman/bin:/usr/local/sdkman/candidates/java/current/bin:/usr/local/sdkman/candidates/gradle/current/bin:/usr/local/sdkman/candidates/maven/current/bin:/usr/local/sdkman/candidates/ant/current/bin:/usr/local/rvm/gems/default/bin:/usr/local/rvm/gems/default@global/bin:/usr/local/rvm/rubies/default/bin:/usr/local/share/rbenv/bin:/usr/local/php/current/bin:/opt/conda/bin:/usr/local/nvs:/usr/local/share/nvm/current/bin:/usr/local/hugo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/share/dotnet:/home/codespace/.dotnet/tools:/usr/local/rvm/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['PATH']) += os.pathsep + '/usr/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:11:12:13:14:15\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /workspaces/vosk-api/python/renzo/model1/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /workspaces/vosk-api/python/renzo/model1/graph/HCLr.fst /workspaces/vosk-api/python/renzo/model1/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /workspaces/vosk-api/python/renzo/model1/graph/phones/word_boundary.int\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# Path to your Vosk model\n",
    "model_path = \"/workspaces/vosk-api/python/renzo/model1\"  # Update with your actual model path\n",
    "\n",
    "# Initialize the Vosk model\n",
    "model = Model(model_path)\n",
    "\n",
    "# Create a KaldiRecognizer with the model and sampling rate\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "# Command to capture audio from Twitch\n",
    "twitch_channel = \"twitch_channel_name\"  # Replace with the Twitch channel name\n",
    "\n",
    "streamlink_command = [\n",
    "    \"streamlink\",\n",
    "    f\"twitch.tv/{twitch_channel}\",\n",
    "    \"audio_only\",\n",
    "    \"-O\",  # Output to stdout\n",
    "]\n",
    "\n",
    "ffmpeg_path = '/usr/bin/ffmpeg'  # Replace with the actual path from 'which ffmpeg'\n",
    "ffmpeg_command = [\n",
    "    \"ffmpeg\",\n",
    "    \"-loglevel\", \"quiet\",  # Suppress ffmpeg output if desired\n",
    "    \"-i\", \"pipe:0\",        # Input from stdin\n",
    "    \"-ac\", \"1\",            # Mono audio\n",
    "    \"-ar\", \"16000\",        # Sampling rate 16000 Hz\n",
    "    \"-f\", \"s16le\",         # Output format\n",
    "    \"pipe:1\",              # Output to stdout\n",
    "]\n",
    "\n",
    "# Start the streamlink process\n",
    "streamlink_process = subprocess.Popen(\n",
    "    streamlink_command,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "# Start the ffmpeg process\n",
    "ffmpeg_process = subprocess.Popen(\n",
    "    ffmpeg_command,\n",
    "    stdin=streamlink_process.stdout,  # Get input from streamlink process\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "# Ensure that streamlink_process.stdout doesn't get closed when ffmpeg_process exits\n",
    "streamlink_process.stdout.close()\n",
    "\n",
    "# Read audio data and transcribe\n",
    "try:\n",
    "    while True:\n",
    "        data = ffmpeg_process.stdout.read(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = recognizer.Result()\n",
    "            text = json.loads(result)[\"text\"]\n",
    "            if text:\n",
    "                print(f\"Transcript: {text}\")\n",
    "        else:\n",
    "            partial_result = recognizer.PartialResult()\n",
    "            partial_text = json.loads(partial_result)[\"partial\"]\n",
    "            # You can print partial results if desired\n",
    "            # print(f\"Partial: {partial_text}\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    ffmpeg_process.kill()\n",
    "    streamlink_process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitch_channel = \"renzoscriber\" "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
